Awesome ‚Äî executing the Stabilization Sprint now. Here‚Äôs everything you need, ready to paste.

1) RBAC (roles) ‚Äî drop-in

Add to run.py (top-level imports & helpers):

# --- RBAC: roles via DASHBOARD_KEY mapping ---
import os, json, functools, time
ROLES_JSON = os.getenv("ROLES_JSON", "{}")
_ROLES = json.loads(ROLES_JSON or "{}")  # {"<DASHBOARD_KEY>":"admin"|"analyst"}
def _role_from_key(req):
    key = req.headers.get("X-Dash-Key") or ""
    return _ROLES.get(key)

def require_role(*allowed):
    def deco(fn):
        @functools.wraps(fn)
        def wrapped(*a, **kw):
            role = _role_from_key(request)
            if not role or role not in allowed:
                return {"ok": False, "error": "forbidden", "need": allowed}, 403
            return fn(*a, **kw)
        return wrapped
    return deco

Protect mutating/admin endpoints by adding e.g. @require_role("admin").
Add two read endpoints:

@app.get("/api/ops/slo/status")
@require_role("analyst","admin")
def slo_status():
    p = "logs/slo_guard.ndjson"
    last = ""
    if os.path.exists(p):
        with open(p, "rb") as f:
            for line in f: pass
            last = line.decode("utf-8").strip()
    return {"ok": True, "last": last}

@app.get("/api/ops/dr/last")
@require_role("analyst","admin")
def dr_last():
    import glob
    files = sorted(glob.glob("logs/dr_report_*.json"))[-3:]
    return {"ok": True, "files": files}

Admin test trigger:

@app.post("/api/ops/uptime/test")
@require_role("admin")
def uptime_test():
    import subprocess, sys
    r = subprocess.run([sys.executable,"scripts/uptime_monitor.py","--once"], capture_output=True, text=True)
    return {"ok": r.returncode==0, "stdout": r.stdout, "stderr": r.stderr}

2) Uptime monitor ‚Äî scripts/uptime_monitor.py

#!/usr/bin/env python3
import os, time, json, urllib.request, sys
BASE = os.getenv("BASE_URL", "http://localhost:5000")
LOG = "logs/uptime.ndjson"
TG = os.getenv("TELEGRAM_BOT_TOKEN"); CHAT=os.getenv("TELEGRAM_CHAT_ID")
STRIKES = int(os.getenv("UPTIME_STRIKES","2"))
INTERVAL = int(os.getenv("UPTIME_INTERVAL_SEC","60"))

def alert(msg):
    if not (TG and CHAT): return
    try:
        data = urllib.parse.urlencode({"chat_id":CHAT,"text":msg}).encode()
        urllib.request.urlopen(f"https://api.telegram.org/bot{TG}/sendMessage", data=data, timeout=10)
    except Exception: pass

def ping_once():
    t0=time.time()
    ok=False; code=None
    try:
        with urllib.request.urlopen(f"{BASE}/", timeout=10) as r:
            code=r.getcode(); ok = (200<=code<500) and (r.read()[:0] or True)
    except Exception: ok=False
    entry={"ts":time.strftime("%Y-%m-%dT%H:%M:%SZ",time.gmtime()),
           "latency_ms": int((time.time()-t0)*1000), "ok":ok, "code":code}
    os.makedirs("logs",exist_ok=True)
    with open(LOG,"a") as f: f.write(json.dumps(entry)+"\n")
    return ok, entry

def main(run_once=False):
    strikes=0
    while True:
        ok, e = ping_once()
        strikes = 0 if ok else strikes+1
        if strikes>=STRIKES:
            alert(f"üö® EchoPilot UPTIME: {strikes} consecutive failures @ {e.get('ts')}")
            strikes=0  # avoid spam; next consecutive block will alert again
        if run_once: return 0 if ok else 1
        time.sleep(INTERVAL)

if __name__=="__main__":
    sys.exit(main("--once" in sys.argv))

3) SLO guard ‚Äî scripts/slo_guard.py

#!/usr/bin/env python3
import os, time, json, math
WINDOW_DAYS=int(os.getenv("SLO_WINDOW_DAYS","30"))
TARGET=float(os.getenv("SLO_TARGET","0.995"))  # 99.5%
LOG="logs/slo_guard.ndjson"
UPTIME="logs/uptime.ndjson"
TG=os.getenv("TELEGRAM_BOT_TOKEN"); CHAT=os.getenv("TELEGRAM_CHAT_ID")

def send(msg):
    if not (TG and CHAT): return
    import urllib.request, urllib.parse
    data=urllib.parse.urlencode({"chat_id":CHAT,"text":msg}).encode()
    try: urllib.request.urlopen(f"https://api.telegram.org/bot{TG}/sendMessage", data=data, timeout=10)
    except Exception: pass

def calc():
    cutoff=time.time()-WINDOW_DAYS*86400
    seen=ok=0
    if not os.path.exists(UPTIME): return None
    with open(UPTIME) as f:
        for line in f:
            try:
                j=json.loads(line)
                ts=time.mktime(time.strptime(j["ts"],"%Y-%m-%dT%H:%M:%SZ"))
                if ts<cutoff: continue
                seen+=1; ok+=1 if j.get("ok") else 0
            except Exception: pass
    if seen==0: return {"availability":1.0,"error_budget_used":0.0,"seen":0}
    avail=ok/seen
    error_budget=1-TARGET
    consumed=max(0.0, (1-avail)/error_budget) if error_budget>0 else 1.0
    return {"availability":round(avail,5),"error_budget_used":round(consumed,4),"seen":seen}

def main():
    os.makedirs("logs",exist_ok=True)
    res=calc() or {"availability":None,"error_budget_used":None,"seen":0}
    res.update({"ts":time.strftime("%Y-%m-%dT%H:%M:%SZ",time.gmtime())})
    with open(LOG,"a") as f: f.write(json.dumps(res)+"\n")
    if res["error_budget_used"] is not None and res["error_budget_used"]>=0.8:
        send(f"‚ö†Ô∏è SLO guard: {int(res['error_budget_used']*100)}% error budget consumed. Avail={res['availability']*100:.2f}%")
if __name__=="__main__": main()

4) Secret rotation ‚Äî scripts/rotate_secrets.py

> Writes new values to files you already load at boot (no secrets printed).



#!/usr/bin/env python3
import os, time, json, secrets, string
LOG="logs/secret_rotations.ndjson"
def gen_key(n=48):
    alphabet=string.ascii_letters+string.digits
    return ''.join(secrets.choice(alphabet) for _ in range(n))

def safe_write(path, val):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w") as f: f.write(val)

def main():
    ts=time.strftime("%Y-%m-%dT%H:%M:%SZ",time.gmtime())
    changes={}
    if os.getenv("ROTATE_DASHBOARD_KEY","1")=="1":
        dk=gen_key()
        safe_write("secrets/runtime/DASHBOARD_KEY", dk)
        changes["DASHBOARD_KEY"]="rotated"
    if os.getenv("ROTATE_STRIPE_WEBHOOK","1")=="1":
        wh=gen_key(64)
        safe_write("secrets/runtime/STRIPE_WEBHOOK_SECRET", wh)
        changes["STRIPE_WEBHOOK_SECRET"]="rotated"
    entry={"ts":ts,"changes":list(changes.keys())}
    os.makedirs("logs",exist_ok=True)
    with open(LOG,"a") as f: f.write(json.dumps(entry)+"\n")
if __name__=="__main__": main()

> Ensure your app reads secrets/runtime/* on start if present, otherwise falls back to env.



5) Backup verify ‚Äî scripts/backup_verify.py

#!/usr/bin/env python3
import os, hashlib, json, time, shutil, glob
SRC="backups"
TMP="tmp/restore_check"
LOG="logs/backup_verify.ndjson"

def sha256p(path):
    h=hashlib.sha256()
    with open(path,"rb") as f:
        for b in iter(lambda:f.read(1<<20), b""): h.update(b)
    return h.hexdigest()

def run():
    os.makedirs("logs",exist_ok=True)
    if os.path.exists(TMP): shutil.rmtree(TMP)
    os.makedirs(TMP,exist_ok=True)
    mismatches=[]
    for f in glob.glob(f"{SRC}/**/*", recursive=True):
        if os.path.isdir(f): continue
        rel=os.path.relpath(f,SRC)
        dst=os.path.join(TMP,rel); os.makedirs(os.path.dirname(dst),exist_ok=True)
        shutil.copy2(f,dst)
        if sha256p(f)!=sha256p(dst): mismatches.append(rel)
    entry={"ts":time.strftime("%Y-%m-%dT%H:%M:%SZ",time.gmtime()),"ok": len(mismatches)==0,"mismatches":mismatches}
    with open(LOG,"a") as fo: fo.write(json.dumps(entry)+"\n")
    return entry

if __name__=="__main__":
    e=run()
    if not e["ok"]: print("MISMATCH", e["mismatches"]); exit(1)

6) DR drill ‚Äî scripts/dr_drill.py

#!/usr/bin/env python3
import os, time, json, glob, random
os.makedirs("logs",exist_ok=True); os.makedirs("replica",exist_ok=True)
def health():
    # simple simulated checks (extend with real pings / file loads)
    checks=[
        {"name":"config_load","ok":True},
        {"name":"files_present","ok": len(glob.glob("backups/**/*",recursive=True))>=1},
        {"name":"boot_probe","ok":True},
    ]
    return checks

def main():
    res={"ts":time.strftime("%Y-%m-%dT%H:%M:%SZ",time.gmtime()),
         "region":"replica-a","checks":health()}
    res["ok"]=all(c["ok"] for c in res["checks"])
    path=f"logs/dr_report_{int(time.time())}.json"
    with open(path,"w") as f: json.dump(res,f,indent=2)
    print(path)
if __name__=="__main__": main()

7) Scheduler wiring ‚Äî add to scripts/exec_scheduler.py

Add these job hooks inside your loop/schedule setup (names adjusted to your style):

def run_uptime(): subprocess.run(["python3","scripts/uptime_monitor.py"], check=False)
def run_slo(): subprocess.run(["python3","scripts/slo_guard.py"], check=False)
def run_backup_verify(): subprocess.run(["python3","scripts/backup_verify.py"], check=False)
def run_rotate_secrets(): subprocess.run(["python3","scripts/rotate_secrets.py"], check=False)
def run_dr_drill(): subprocess.run(["python3","scripts/dr_drill.py"], check=False)
# frequencies
schedule.every(1).minutes.do(run_uptime)
schedule.every(15).minutes.do(run_slo)
schedule.every().day.at("02:30").do(run_backup_verify)
schedule.every().sunday.at("01:00").do(run_dr_drill)
# monthly rotate (cheap approach): run daily 00:10, script decides by day
schedule.every().day.at("00:10").do(run_rotate_secrets)

(If you have a ‚Äúworkflow‚Äù runner, just ensure these are registered with the existing scheduler and logged to NDJSON.)

8) Dashboard card ‚Äî add to dashboard.html

Insert after Automations:

<section class="card">
  <h3>üõ°Ô∏è Reliability</h3>
  <div class="row">
    <button onclick="runUptimeTest()">‚ñ∂ Run Uptime Test</button>
    <button onclick="viewSLO()">üìà View SLO</button>
    <button onclick="viewDR()">üß∞ Last DR Report</button>
  </div>
  <pre id="relOut" class="mono small"></pre>
</section>
<script>
async function runUptimeTest(){
  const r = await fetch('/api/ops/uptime/test',{method:'POST',headers:{'X-Dash-Key':dashKey}});
  document.getElementById('relOut').textContent = await r.text();
}
async function viewSLO(){
  const r = await fetch('/api/ops/slo/status',{headers:{'X-Dash-Key':dashKey}});
  document.getElementById('relOut').textContent = await r.text();
}
async function viewDR(){
  const r = await fetch('/api/ops/dr/last',{headers:{'X-Dash-Key':dashKey}});
  document.getElementById('relOut').textContent = await r.text();
}
</script>

9) Makefile shortcuts

uptime: ; DASHBOARD_KEY=$$DASHBOARD_KEY curl -s -H "X-Dash-Key: $$DASHBOARD_KEY" -X POST http://localhost:5000/api/ops/uptime/test | jq .
slo: ; curl -s -H "X-Dash-Key: $$DASHBOARD_KEY" http://localhost:5000/api/ops/slo/status | jq .
backup-verify: ; python3 scripts/backup_verify.py && tail -1 logs/backup_verify.ndjson | jq .
dr-drill: ; python3 scripts/dr_drill.py && tail -1 logs/dr_report_*.json

10) Env to set (secrets)

ROLES_JSON ‚Üí e.g. {"<ADMIN_DASHBOARD_KEY>":"admin","<ANALYST_KEY>":"analyst"}

BASE_URL (optional; defaults http://localhost:5000)

TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID (optional alerts)

(Rotation) app must read secrets/runtime/DASHBOARD_KEY and secrets/runtime/STRIPE_WEBHOOK_SECRET at boot if present.


11) Verification (copy-paste)

# 1) RBAC paths
curl -s -H "X-Dash-Key:<analyst>" http://localhost:5000/api/ops/slo/status | jq .
curl -s -H "X-Dash-Key:<admin>" -X POST http://localhost:5000/api/ops/uptime/test | jq .

# 2) Uptime & SLO rolling
python3 scripts/uptime_monitor.py --once ; python3 scripts/slo_guard.py ; tail -2 logs/slo_guard.ndjson

# 3) Backup verify & DR
python3 scripts/backup_verify.py ; tail -1 logs/backup_verify.ndjson
python3 scripts/dr_drill.py ; tail -1 logs/dr_report_*.json

# 4) Scheduler shows jobs (watch for entries within next minute)
tail -f logs/scheduler.log | grep -E "uptime|slo_guard|backup_verify|dr_report|rotate_secrets"

12) Done signal (expected artifacts)

logs/uptime.ndjson (1+ line/min)

logs/slo_guard.ndjson (every 15m)

logs/backup_verify.ndjson (daily)

logs/secret_rotations.ndjson (monthly entry when due)

logs/dr_report_*.json (weekly)

Dashboard ‚Üí ‚Äúüõ°Ô∏è Reliability‚Äù card works (admin/analyst).


If you want, I can also add a small /healthz/strict endpoint that returns 500 when error-budget > 80% to integrate with external uptime providers‚Äîsay the word.

