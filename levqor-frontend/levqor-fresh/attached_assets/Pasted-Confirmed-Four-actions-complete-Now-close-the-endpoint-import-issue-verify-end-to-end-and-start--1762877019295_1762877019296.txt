Confirmed. Four actions complete. Now close the endpoint import issue, verify end-to-end, and start the 7-day burn-in.

Immediate hotfix + validation (single runbook)

#!/usr/bin/env bash
set -euo pipefail

echo "== 1) Patch intelligence endpoints to use the new PostgreSQL adapter =="
# Adjust paths if your repo structure differs.
# Replace old adapter imports with the new one.
apply_sed() {
  local f="$1"
  if grep -qE "from modules\.auto_intel\.db_adapter import|get_pg" "$f"; then
    echo "[skip] $f already on new adapter"
  else
    # Common old patterns covered: modules.db, services.db, app.db, db import get_pg/pg
    sed -i -E \
      -e 's@from (modules|services|app)\.db import (get_pg|pg)@from modules.auto_intel.db_adapter import get_pg@g' \
      -e 's@import (modules|services|app)\.db as db@from modules.auto_intel.db_adapter import get_pg@g' \
      -e 's@\bdb\.get_pg\(\)@get_pg()@g' \
      -e 's@\bpg\.connection\(\)@get_pg()@g' \
      "$f"
    echo "[patched] $f"
  fi
}

# Target the API routes and any intelligence helpers.
for f in \
  api/routes/intelligence.py \
  api/routes/intelligence/*.py \
  modules/auto_intel/*.py \
  ; do
  [ -f "$f" ] && apply_sed "$f" || true
done

echo "== 2) Static import sanity check =="
python - <<'PY'
import importlib, sys
mods = [
  "modules.auto_intel.db_adapter",
  "api.routes.intelligence",
]
ok=True
for m in mods:
    try:
        importlib.import_module(m)
        print("[ok] import", m)
    except Exception as e:
        ok=False
        print("[fail] import", m, "->", repr(e), file=sys.stderr)
sys.exit(0 if ok else 1)
PY

echo "== 3) Run CI smoke + security tests =="
pytest -q tests/test_intelligence_ci.py
if [ -f ".env.staging" ]; then
  set -a; source .env.staging; set +a
  pytest -q tests/test_tenancy_security.py
fi

echo "== 4) Live health and intelligence checks =="
# Adjust domains if needed.
BASE="https://api.levqor.ai"
set +e
curl -fsS "$BASE/health" | jq '.'
curl -fsS "$BASE/api/intelligence/status" | jq '.'
curl -fsS "$BASE/api/intelligence/forecasts" | jq '.'
curl -fsS "$BASE/api/intelligence/health" | jq '.'
curl -fsS "$BASE/api/intelligence/anomalies" | jq '.'
curl -fsS "$BASE/api/intelligence/recommendations" | jq '.'
set -e

echo "== 5) Response contract spot-checks =="
# Fail fast if required keys are missing. Adjust keys to your schema.
check_key () { jq -e "has(\"$2\")" >/dev/null || { echo "[fail] $1 missing key: $2"; exit 1; }; }
resp_status=$(curl -fsS "$BASE/api/intelligence/status")
echo "$resp_status" | check_key status uptime_7d
resp_forecasts=$(curl -fsS "$BASE/api/intelligence/forecasts")
echo "$resp_forecasts" | jq '.[0]' >/dev/null 2>&1 || { echo "[fail] forecasts not array-like"; exit 1; }

echo "== 6) APScheduler inventory (expect 18 jobs) =="
python - <<'PY'
# Minimal read-only job inventory; adjust import to your scheduler wiring.
try:
    from monitors.scheduler import scheduler
    jobs = scheduler.get_jobs()
    print("jobs:", len(jobs))
    assert len(jobs) >= 18, f"expected >=18, got {len(jobs)}"
    for j in jobs:
        print("-", j.id, j.trigger)
except Exception as e:
    print("[warn] could not introspect scheduler:", e)
PY

echo "== 7) Synthetic checks + Go/No-Go dashboard (on-demand run) =="
python3 scripts/monitoring/synthetic_checks.py || true
python3 scripts/monitoring/notion_go_nogo_dashboard.py || true

echo "== 8) Sentry ping =="
python - <<'PY'
try:
    from config.sentry_config import sentry_sdk
    with sentry_sdk.push_scope() as scope:
        scope.set_tag("healthcheck","manual-ping")
        sentry_sdk.capture_message("manual sentry ping: intelligence hotfix verification")
    print("[ok] sentry ping queued")
except Exception as e:
    print("[warn] sentry ping failed:", e)
PY

echo "== 9) Commit =="
git add -A
git commit -m "intel: switch endpoints to modules.auto_intel.db_adapter + verify + burn-in start" || true

echo "All checks executed."

Burn-in plan (7 days)

Daily 09:00 UTC: run the dashboard and record the 5 gate metrics in your ops log.

Track “Intelligence API Days” counter. Goal: ≥7 by Nov 24, 09:00 UTC.

Watch error-rate and 5xx burst alerts. Any alert pauses the counter that day.

Keep Sentry at 10% sample. If cost pressure rises, drop to 5% but keep traces on the intelligence routes.


Quick risk controls

Rollback: keep the verified dump path pinned in the ops runbook. Perform a 1-minute restore drill mid-week.

Rate limiting: ensure /api/intelligence/* behind your standard limiter to avoid noisy synthetic traffic.

Cost guard: until Replit usage API is wired, estimate daily spend from OpenAI usage + Vercel logs and enforce the $10/day soft cap in alerting.py.


Go/No-Go on Mon, Nov 24, 2025 09:00 UTC

Proceed “GO” only if: uptime ≥ 99.98% over 7 days, error rate ≤ 0.5% past 24h, 0 P1s past 7 days, Intelligence API Days ≥ 7, daily cost ≤ $10.

If any fail: mark “NO-GO,” extend monitoring one week, fix the failing dimension first.


If you want, I can set a reminder for the Nov 24 review.